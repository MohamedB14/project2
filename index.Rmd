---
title: 'Project 2: Data Mining, Classification, Prediction'
author: "SDS322E"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))

class_diag <- function(score, truth, positive, cutoff=.5){

  pred <- factor(score>cutoff,levels=c("TRUE","FALSE"))
  truth <- factor(truth==positive, levels=c("TRUE","FALSE"))

  tab<-table(truth, pred)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[1,1]/rowSums(tab)[1]
  spec=tab[2,2]/rowSums(tab)[2]
  ppv=tab[1,1]/colSums(tab)[1]

#CALCULATE F1
  f1=2*(sens*ppv)/(sens+ppv)
  
#CALCULATE EXACT AUC
  truth<-as.numeric(truth=="TRUE")
  ord<-order(score, decreasing=TRUE)
  score <- score[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(score[-1]>=score[-length(score)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  round(data.frame(acc,sens,spec,ppv,f1,ba=(sens+spec)/2,auc, row.names = "Metrics"),4)
}
```

# Mining, Classification, Prediction

## Mohamed Bettayeb, mb58422

### Introduction 

My dataset consists of data collected from incidents of heart failures at hospitals. The variables included in this dataset are age, anaemia, creatinine_phosphokinase, diabetes, ejection_fraction, high_blood_pressure, platelets, serum_creatinine, serum_sodium, sex, smoking, time, and DEATH_EVENT. I found this data on kaggle.com. My variables are measuring certian statuses and data collected by the hospitals of the patients that had an incident of heart failure. Age marks the age of the patient. Anaemia marks whether or not the patient had a deficiency in red blood cells. Creatinine_phosphokinase, serum_creatinine, aand serum_sodium are variables that measure how much of their respective chemicals are in the patient's bloodstream. Ejection fraction measures the amount of blood leaving the heart. Diabetes marks whether or not the patient has diabetes. High_blood_pressure marks whether or not the patient has high blood pressure. Platelets measures the platelet count of the patient. Sex marks the sex of the patient. Smoking marks whether or not the patient is a smoker. Time measures the follow-up period. DEATH_EVENT marks whether or not this heart failure was fatal. I found this data particularly interesting as it has a lot to do with a particular field that I am interested in pursuing a career in one day; cardiology. There are approximately 299 observations of all 13 variables. 

```{R}
library(tidyverse)
library(dplyr)
library(readr)
library(gt)
# read your datasets in here, e.g., with read_csv()
heart_failure <- read_csv("heart_failure_clinical_records_dataset.csv")
# if your dataset needs tidying, do so here

# any other code here
```

### Cluster Analysis

```{R}
library(cluster)
library(ggplot2)
library(GGally)
pam_data <-heart_failure %>% select(age, creatinine_phosphokinase, ejection_fraction, platelets, serum_creatinine, serum_sodium, time)
sil_width <- vector()
for (i in 2:10){
  pam_fit <- pam(pam_data, k = i)
  sil_width[i] <- pam_fit$silinfo$avg.width
}
pam_fit <- pam(pam_data, k = 9)
pam_fit$silinfo$avg.width
ggplot() + geom_line(aes(x=1:10, y=sil_width)) + scale_x_continuous(name="k", breaks=1:10)
# 9 is the ideal k
pam1 <- heart_failure %>% select(age, creatinine_phosphokinase, ejection_fraction, platelets, serum_creatinine, serum_sodium, time) %>% pam(k=9)
pamclust <- heart_failure %>% select(age, creatinine_phosphokinase, ejection_fraction, platelets, serum_creatinine, serum_sodium, time) %>% mutate(cluster=as.factor(pam1$clustering))
ggpairs(pamclust, columns = 1:7,aes(color=cluster))
pamclust %>% group_by(cluster) %>% summarize_if(is.numeric, 
    mean, na.rm = T)


```

The ggplot suggested 9 clusters for this dataset. The average silhouette width for this cluster bunch is 0.592498 indicating that this is a reasonable structure. Prior to performing the PAM function, the numeric variables of the Presidents data set were isolated, using the select() function and the following variables were selected for: age, creatinine_phosphokinase, ejection_fraction, platelets, serum_creatinine, serum_sodium, and time. 

While the cluster bunch indicates that this is a reasonable structure, the ggpairs plot is still a relatively difficult one to interpret. Moreover, due to the number of clusters and their similarities, it is rather difficut to differentiate between them.
    
    
### Dimensionality Reduction with PCA

```{R}
# PCA code here
h1 <- heart_failure %>% select(age, creatinine_phosphokinase, ejection_fraction, platelets, serum_creatinine, serum_sodium, time)
heartnums <- h1 %>% select_if(is.numeric) %>% scale
heartpca <- princomp(heartnums)
names(heartpca)
eigval <- heartpca$sdev^2
round(cumsum(eigval)/sum(eigval), 2)
heartdf <- data.frame(PC1 = heartpca$scores[,1], PC2 = heartpca$scores[,2], PC3= heartpca$scores[,3],PC4 = heartpca$scores[,4], PC5 = heartpca$scores[,5])
ggpairs(heartdf, columns = 1:5)
summary(heartpca, loadings = T)
```

Based on the comps, it was found that the five PCs make up for about 80% of the variance. The summary above indicates that for PC1, every loading was negative except for age and serum creatinine. PC2 had only creatinine phosphokinase and time as the negative loading. PC3 had two positive loadings, time and ejection fraction. PC4 had 3 positive loadings: age, creatinine phosphokinase, and serum sodium. PC5 had 3 positive loadings: age, platelets, and serum sodium. While there doesn't seem to be a strong correlation with any of these loadings, it was rather interesting that age was always positive and that time was always negative. This would make sense, as the older someone is, the more urgent their follow up period would likely be.

###  Linear Classifier

```{R}
# linear classifier code here
fit <- glm(anaemia ~ age + creatinine_phosphokinase + ejection_fraction + platelets + serum_creatinine + serum_sodium + time, data = heart_failure, family= "binomial")
score <- predict(fit, type="response")
class_diag(score, heart_failure$anaemia, positive = 1)
table(predict=as.numeric(score >.5),truth=heart_failure$anaemia)%>%addmargins
```

```{R}
# cross-validation of linear classifier here
set.seed(1234)
k=10 #choose number of folds
heartdata<-heart_failure[sample(nrow(heart_failure)),] #randomly order rows
folds<-cut(seq(1:nrow(heart_failure)),breaks=k,labels=F) #create 10 folds
diags<-NULL
for(i in 1:k){
  ## Create training and test sets
  train<-heartdata[folds!=i,] 
  test<-heartdata[folds==i,]
  truth<-test$anaemia
  ## Train model on training set
  fit<-glm(anaemia~.,data=train,family="binomial")
  probs<-predict(fit,newdata = test,type="response")
  ## Test model on test set (save all k results)
  diags<-rbind(diags,class_diag(probs,truth, positive=1))
}
summarize_all(diags,mean)
```

The CV AUV indicates that this model is bad at predicting new observations with an AUC of 0.55897. There are signs of overfitting in this model, as the AUC of the initial linear regression is 0.6489, which is significantly higher than that of the CV AUC.

### Non-Parametric Classifier

```{R}
library(caret)
knn_fit <- knn3(factor(anaemia==1,levels=c("TRUE","FALSE")) ~., data=heart_failure, k=5)
y_hat_knn <- predict(knn_fit,heart_failure)
class_diag(y_hat_knn[,1],heart_failure$anaemia, positive=1)
table(predicted=as.numeric(y_hat_knn[,1] >.5),actual=heart_failure$anaemia)%>%addmargins

```

```{R}
# cross-validation of np classifier here
set.seed(1234)
k=5 #choose number of folds
cvdata<-heart_failure %>% sample_frac() #randomly order rows
folds<-cut(seq(1:nrow(heart_failure)),breaks=k,labels=F) #create folds
diags<-NULL
for(i in 1:k){
  cvtrain<-cvdata[folds!=i,]
  cvtest<-cvdata[folds==i,]
  ## Fit linear regression model to training set
  cvfit<-knnreg(anaemia~.,data=cvtrain)
  ## Get predictions/y-hats on test set (fold i)
  cvyhat<-predict(cvfit,newdata=cvtest)
  ## Compute prediction error  (MSE) for fold i
  cvdiags<-mean((cvtest$anaemia-cvyhat)^2) 
}
mean(cvdiags) ## get average MSE across all folds (much higher error)!

```

The CV MSE indicates that this model is overfitting as it is quite low at 0.3028333. furthermore, the AUC of the model indicates that this model is fair at predicting new observations at 0.7636.


### Regression/Numeric Prediction

```{R}
# regression model code here
lrfit<-lm(age~.,data=heart_failure) #predict mpg from all other variables
lryhat<-predict(lrfit) #predicted mpg
mean((heart_failure$age-lryhat)^2)
```

```{R}
# cross-validation of regression model here
set.seed(1234)
k=5 #choose number of folds
lcvdata<-heart_failure[sample(nrow(heart_failure)),] #randomly order rows
lcvfolds<-cut(seq(1:nrow(heart_failure)),breaks=k,labels=F) #create folds
diags<-NULL
for(i in 1:k){
  lcvtrain<-lcvdata[lcvfolds!=i,]
  lcvtest<-lcvdata[lcvfolds==i,]
  ## Fit linear regression model to training set
  lcvfit<-lm(age~.,data=lcvtrain)
  ## Get predictions/y-hats on test set (fold i)
  lcvyhat<-predict(fit,newdata=lcvtest)
  ## Compute prediction error  (MSE) for fold i
  lcvdiags<-mean((test$age-lcvyhat)^2) 
}
mean(lcvdiags) ## get average MSE across all folds (much higher error)!
```

This model does show signs of overfitting as the CV MSE is much higher than the model error. The model error is 123.3761, while the MSE is 3780.581, which makes the MSE more than 10x times larger in the CV, indicating overfitting.

### Python 

```{R}
library(reticulate)

math <- 59
```

```{python}
# python code here
math = 58
print(r.math + math)
```

```{R}
sum <- sum(math, py$math)
sum
```

I stored the number 59 into a variable named "math" in the r code chunk, I then stored a number of 58 in a variable of the same name in the python chunk. I then utilized reticulate to access the r code math variable in the python chunk and then added the two and printed the sum. Utilizing reticulate again, I did a similar thing in the r code chunk, except this time accessing the python math variable and printing the sum.

### Concluding Remarks






